# predicting whether patient will be readmitted or not
# if prob > 1/2 then patient will not readmit
logit.pred.1 <- rep(F, nrow(diabetic[-train,]))
logit.pred.1[logit.prob.1 > 0.5] <- T
# test error
mse.3 <- mean((logit.pred.1-diabetic$isReadmitted[-train])^2)
mse.3
sink("logit_output.txt")  # start outputing to text file
resetData <- reset()  # reset data
diabetic <- resetData[[1]]
train <- resetData[[2]]
get <- resetData[[3]]
# update formula
# also exclude admission_type_id, discharge_disposition_id, admission_source_id
# and medical_specialty
# Reason: error in dataset jams logit
varnames <- paste(c(names(diabetic
[,-c(get,1,2,6,7,8,9,11,12,19,20,21,33,38,45,46,50,51)])), collapse = "+")
formula <- paste(c("isReadmitted",varnames), collapse = "~")
# fit logit using training data
logit.1 <- glm(formula, data = diabetic, family = "binomial", subset=train)
cat("Do logit on training set\n")
summary(logit.1)  # very sparse results, many vars individually insignificant, jointly??
#plot(logit.1)  # kinda useful?
# predict probability of readmission using test data
logit.prob.1 <- predict(logit.1, newdata = diabetic[-train,], type = "response")
cat("\nPredict using test set\n")
summary(logit.prob.1)
hist(logit.prob.1)
# predicting whether patient will be readmitted or not
# if prob > 1/2 then patient will not readmit
logit.pred.1 <- rep(F, nrow(diabetic[-train,]))
logit.pred.1[logit.prob.1 > 0.5] <- T
# test error
mse.3 <- mean((logit.pred.1-diabetic$isReadmitted[-train])^2)
cat("\nMSE\n")
mse.3
cat("\nConfusion matrix\n")
# confusion matrix
table(logit.pred.1, diabetic$isReadmitted[-train])
# 5188 actually readmitted but predicted not readmitted, type-1 error is greater, not good
# 2218 actually not readmitted but predicted readmitted
cat("\nAccuracy\n")
mean(logit.pred.1 == diabetic$isReadmitted[-train])
# 60.6% of our prediction was correct, not bad
cat("\nNOTICE,\n")
mse.3 + mean(logit.pred.1 == diabetic$isReadmitted[-train]) # =1!
sink()  # stop writing to text file
sink("logit_output.txt")  # start outputing to text file
resetData <- reset()  # reset data
diabetic <- resetData[[1]]
train <- resetData[[2]]
get <- resetData[[3]]
# update formula
# also exclude admission_type_id, discharge_disposition_id, admission_source_id
# and medical_specialty
# Reason: error in dataset jams logit
varnames <- paste(c(names(diabetic
[,-c(get,1,2,6,7,8,9,11,12,19,20,21,33,38,45,46,50,51)])), collapse = "+")
formula <- paste(c("isReadmitted",varnames), collapse = "~")
# fit logit using training data
logit.1 <- glm(formula, data = diabetic, family = "binomial", subset=train)
cat("Do logit on training set\n")
summary(logit.1)  # very sparse results, many vars individually insignificant, jointly??
#plot(logit.1)  # kinda useful?
# predict probability of readmission using test data
logit.prob.1 <- predict(logit.1, newdata = diabetic[-train,], type = "response")
cat("\nPredict using test set\n")
summary(logit.prob.1)
hist(logit.prob.1)
# predicting whether patient will be readmitted or not
# if prob > 1/2 then patient will not readmit
logit.pred.1 <- rep(F, nrow(diabetic[-train,]))
logit.pred.1[logit.prob.1 > 0.5] <- T
# test error
mse.3 <- mean((logit.pred.1-diabetic$isReadmitted[-train])^2)
cat("\nMSE\n")
mse.3
cat("\nConfusion matrix\n")
# confusion matrix
table(logit.pred.1, diabetic$isReadmitted[-train])
# 5188 actually readmitted but predicted not readmitted, type-1 error is greater, not good
# 2218 actually not readmitted but predicted readmitted
cat("\nAccuracy\n")
mean(logit.pred.1 == diabetic$isReadmitted[-train])
# 60.6% of our prediction was correct, not bad
cat("\nNOTICE, sum of MSE and accuracy = \n")
mse.3 + mean(logit.pred.1 == diabetic$isReadmitted[-train]) # =1!
sink()  # stop writing to text file
png(filename="lassoCV.png")  # save plot
plot(cv.lasso.1)
dev.off()
library(nnet)
library(pscl)
resetData <- reset()  # reset data
diabetic <- resetData[[1]]
train <- resetData[[2]]
get <- resetData[[3]]
# use formula from above logit but for readmitted, not isReadmitted
formula <- paste(c("readmitted",varnames), collapse = "~")
# fit multinomial
nn.1 <- multinom(formula, data = diabetic[train,])
length(nn.1$coefnames)  # number of features
summary(nn.1$fitted.values)
nn.1$edf  # effective DF exhausted up by model
nn.1$deviance  # residual deviance, minus twice log-likelihook
nn.1$AIC
# predict probability of days between readmission using test data
nn.pred.1 <- predict(nn.1, newdata = diabetic[-train,], type = "probs")
# predict intervals between readmission using test data
nn.class.1 <- predict(nn.1, newdata = diabetic[-train,])
# confusion matrix
library(caret)
caret::confusionMatrix(as.factor(nn.class.1),
as.factor(diabetic[-train,]$readmitted))
sink("nn_output.txt")  # start outputing to text file
library(nnet)
library(pscl)
resetData <- reset()  # reset data
diabetic <- resetData[[1]]
train <- resetData[[2]]
get <- resetData[[3]]
# use formula from above logit but for readmitted, not isReadmitted
formula <- paste(c("readmitted",varnames), collapse = "~")
# fit multinomial
nn.1 <- multinom(formula, data = diabetic[train,])
cat("Fit multinomial logistic neural net and get number of features
in model, probabilities, and effective DF\n")
length(nn.1$coefnames)  # number of features
summary(nn.1$fitted.values)
nn.1$edf  # effective DF exhausted up by model
#nn.1$deviance  # residual deviance, minus twice log-likelihook
#nn.1$AIC  # AIC for fit
# predict probability of days between readmission using test data
nn.pred.1 <- predict(nn.1, newdata = diabetic[-train,], type = "probs")
# predict intervals between readmission using test data
nn.class.1 <- predict(nn.1, newdata = diabetic[-train,])
cat("\nConfusion matrix\n")
# confusion matrix
library(caret)
caret::confusionMatrix(as.factor(nn.class.1),
as.factor(diabetic[-train,]$readmitted))
# test error
mse.4 <- mean(as.character(nn.class.1)!=
as.character(diabetic[-train,]$readmitted), na.rm = T)
cat("\nMSE\n")
mse.4
sink()  # stop writing to text file
# calculate z score and p values
c <- summary(nn.1)$coefficients
se <- summary(nn.1)$standard.errors
z <- c/se
p <- (1-pnorm(abs(z),0,1))*2 # I am using two-tailed z test
#z
#p
summ <- as.data.frame(rbind(c[2,],se[2,],z[2,],p[2,]))
rownames(summ) <- c("Coefficient","Std. Errors","Z stat","P-value")
summ <- t(summ)
png(filename="nn1.png")  # save plot
# make neat table
library(knitr)
library(kableExtra)
library(dplyr)
#summ %>%
#  mutate_if(is.numeric, function(x) {
#    cell_spec(x, bold = T,
#              color = spec_color(x, end=0),
#              font_size = spec_font_size(x, end = 12))
#  }) %>%
kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
dev.off()
this <- kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
save_kable(this)
save_kable(this, .png)
save_kable(this, nn1.png)
#summ %>%
#  mutate_if(is.numeric, function(x) {
#    cell_spec(x, bold = T,
#              color = spec_color(x, end=0),
#              font_size = spec_font_size(x, end = 12))
#  }) %>%
save_kable( kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, nn1.png)
#summ %>%
#  mutate_if(is.numeric, function(x) {
#    cell_spec(x, bold = T,
#              color = spec_color(x, end=0),
#              font_size = spec_font_size(x, end = 12))
#  }) %>%
save_kable( kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, "nn1.png")
#summ %>%
#  mutate_if(is.numeric, function(x) {
#    cell_spec(x, bold = T,
#              color = spec_color(x, end=0),
#              font_size = spec_font_size(x, end = 12))
#  }) %>%
save_kable( kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, ".png")
webshot::install_phantomjs()
#summ %>%
#  mutate_if(is.numeric, function(x) {
#    cell_spec(x, bold = T,
#              color = spec_color(x, end=0),
#              font_size = spec_font_size(x, end = 12))
#  }) %>%
save_kable( kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, "nn1.png")
#summ %>%
#  mutate_if(is.numeric, function(x) {
#    cell_spec(x, bold = T,
#              color = spec_color(x, end=0),
#              font_size = spec_font_size(x, end = 12))
#  }) %>%
save_kable( kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, "nn1.png")
library(magick)
# install packages when needed
#install.packages("naniar")
#install.packages("car")
#install.packages("fitdistrplus")
#install.packages("hdm")
#install.packages("stringr")
#install.packages("caret")
#install.packages("kableExtra")
install.packages("magick")
#summ %>%
#  mutate_if(is.numeric, function(x) {
#    cell_spec(x, bold = T,
#              color = spec_color(x, end=0),
#              font_size = spec_font_size(x, end = 12))
#  }) %>%
save_kable( kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, "nn1.png")
sink("nn_output2.txt")  # start outputing to text file
# calculate important variables
impvars <- varImp(nn.1)
impvars$Variables <- row.names(impvars)
impvars <- impvars[order(-impvars$Overall),]
cat("Look at first few most important variables\n")
head(impvars)
# choose variables that matter
imp1 <- names(summ)[which(p[2,-1]<0.001)]  # individual significance
imp2 <- impvars$Variables[which(impvars$Overall>1)]  # overall importance
critvars <- union(imp1, imp2)
# make formula
varnames <- paste(critvars, collapse = "+")
formula <- paste(c("readmitted",varnames), collapse = "~")
# name all extra variables created
diabetic$age10_20 <- diabetic$age == "10_20"
diabetic$age20_30 <- diabetic$age == "20_30"
diabetic$age30_40 <- diabetic$age == "30_40"
diabetic$age40_50 <- diabetic$age == "40_50"
diabetic$age50_60 <- diabetic$age == "50_60"
diabetic$age60_70 <- diabetic$age == "60_70"
diabetic$age70_80 <- diabetic$age == "70_80"
diabetic$age80_90 <- diabetic$age == "80_90"
diabetic$age90_100 <- diabetic$age == "90_100"
diabetic$metforminUp <- diabetic$metformin == "Up"
diabetic$repaglinideNo <- diabetic$repaglinide == "No"
diabetic$repaglinideSteady <- diabetic$repaglinide == "Steady"
diabetic$repaglinideUp <- diabetic$repaglinide == "Up"
diabetic$nateglinideNo <- diabetic$nateglinide == "No"
diabetic$chlorpropamideSteady <- diabetic$chlorpropamide == "Steady"
diabetic$pioglitazoneUp <- diabetic$pioglitazone == "Up"
diabetic$rosiglitazoneNo <- diabetic$rosiglitazone == "No"
diabetic$rosiglitazoneSteady <- diabetic$rosiglitazone == "Steady"
diabetic$rosiglitazoneUp <- diabetic$rosiglitazone == "Up"
diabetic$acarboseNo <- diabetic$acarbose == "No"
diabetic$acarboseSteady <- diabetic$acarbose == "Steady"
diabetic$acarboseUp <- diabetic$acarbose == "Up"
diabetic$miglitolSteady <- diabetic$miglitol == "Steady"
diabetic$insulinUp <- diabetic$insulin == "Up"
diabetic$glyburide.metforminNo <- diabetic$glyburide.metformin == "No"
diabetic$glyburide.metforminSteady <-
diabetic$glyburide.metformin == "Steady"
diabetic$changeNo <- diabetic$change == "No"
diabetic$chlorpropamideUp <- diabetic$chlorpropamide == "Up"
diabetic$miglitolUp <- diabetic$miglitol == "Up"
diabetic$nateglinideUp <- diabetic$nateglinide == "Up"
diabetic$glipizide.metforminSteady <-
diabetic$glipizide.metformin == "Steady"
diabetic$tolazamideUp <- diabetic$tolazamide == "Up"
diabetic$miglitolNo <- diabetic$miglitol == "No"
diabetic$metformin.pioglitazoneSteady <-
diabetic$metformin.pioglitazone == "Steady"
diabetic$glyburide.metforminUp <- diabetic$glyburide.metformin == "Up"
cat("\nFit multinomial logistic neural net and get number of features
in model, probabilities, and effective DF\n")
# do multinomial logistic neural nets
nn.2 <- multinom(formula, data = diabetic[train,])
length(nn.2$coefnames)  # number of features
summary(nn.2$fitted.values)
nn.2$edf  # effective DF exhausted up by model
#nn.2$deviance  # residual deviance, minus twice log-likelihook
#nn.2$AIC  # AIC for fit
# predict probability of days between readmission using test data
nn.pred.2 <- predict(nn.2, newdata = diabetic[-train,], type = "probs")
# predict intervals between readmission using test data
nn.class.2 <- predict(nn.2, newdata = diabetic[-train,])
# confusion matrix
caret::confusionMatrix(as.factor(nn.class.2),
as.factor(diabetic[-train,]$readmitted))
# test error
mse.4.5 <- mean(na.omit(as.character(nn.class.2) !=
as.character(diabetic[-train,]$readmitted)))
cat("\nMSE\n")
mse.4.5  # reduced only by about 0.001 after eliminating half the variables
sink()  # stop writing to text file
# calculate z score and p values
c2 <- summary(nn.2)$coefficients
se2 <- summary(nn.2)$standard.errors
z2 <- c2/se2
p2 <- (1-pnorm(abs(z2),0,1))*2 # I am using two-tailed z test
#z2
#p2
summ2 <- as.data.frame(rbind(c2[2,],se2[2,],z2[2,],p2[2,]))
rownames(summ2) <- c("Coefficient","Std. Errors","Z stat","P-value")
summ2 <- t(summ2)
# make neat table
save_kable(
kable(summ2, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, "nn1.png")
save_kable(
kable(summ2, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, "nn2.png")
save_kable(
kable(summ, escape = F) %>%
kable_styling(fixed_thead = T, bootstrap_options =
c("striped", "condensed", "responsive"),
full_width = F, font_size = 12)
, "nn1.png")
sink("boosting.txt")  # start outputing to text file
resetData <- reset()  # reset data
diabetic <- resetData[[1]]
train <- resetData[[2]]
get <- resetData[[3]]
varnames <- resetData[[4]]
formula <- resetData[[5]]
## Author: Tatsuya Okuda
## Date: 06/08/2019 --------------------------------------
set.seed(987)
diabetic.sub = diabetic[,-c(get,1,2,6,7,8,9,11,12,19,20,21,33,38,45,46,50)]
varnames <- paste(c(names(diabetic
[,-c(get,1,2,6,7,8,9,11,12,19,20,21,33,38,45,46,50,51)])), collapse = "+")
formula <- paste(c("isReadmitted",varnames), collapse = "~")
formula = as.formula(formula)
diabetic = na.omit(diabetic.sub) #omit NA
train = sample(1:nrow(diabetic.sub), floor(nrow(diabetic.sub)*0.7))
test = setdiff(1:nrow(diabetic.sub), train)
library(gbm)
boosting = gbm(formula,data=diabetic.sub[train,], distribution = "bernoulli",
n.trees = 1000, interaction.depth = 4)
cat("Do boosting\n")
summary(boosting)
boosting.pred = predict.gbm(boosting, newdata = diabetic.sub[test,],
n.trees = 1000, type = "response")
prediction = rep(0,length(test))
prediction[boosting.pred>0.5] = "TRUE"
prediction[boosting.pred<=0.5] = "FALSE"
diabetic.sub$isReadmitted[diabetic.sub$isReadmitted==0] = "FALSE"
diabetic.sub$isReadmitted[diabetic.sub$isReadmitted==1] = "TRUE"
correct = sum(prediction == diabetic.sub$isReadmitted[test])
total = length(test)
accuracy = correct/total
cat("\nAccuracy\n")
accuracy
## end ---------------------------------------------------
sink()
sink("randomforest.txt")  # start outputing to text file
resetData <- reset()  # reset data
diabetic <- resetData[[1]]
train <- resetData[[2]]
get <- resetData[[3]]
varnames <- resetData[[4]]
formula <- resetData[[5]]
## Author: Tatsuya Okuda
## Date: 06/08/2019 --------------------------------------
diabetic$isReadmitted = as.factor(diabetic$isReadmitted) #factor
#remove medical specialty because RF does not work for too many levels
set.seed(987)
diabetic.sub = diabetic[,-c(get,1,2,6,7,8,9,11,12,19,20,21,33,38,45,46,50)]
diabetic.sub = na.omit(diabetic.sub) #omit NA
train = sample(1:nrow(diabetic.sub), floor(nrow(diabetic.sub)*0.7))
test = setdiff(1:nrow(diabetic.sub), train)
varnames <- paste(c(names(diabetic
[,-c(get,1,2,6,7,8,9,11,12,19,20,21,33,38,45,46,50,51)])), collapse = "+")
formula <- paste(c("isReadmitted",varnames), collapse = "~")
formula = as.formula(formula)
library(randomForest)
cat("Do random forest on training set\n")
rf = randomForest(formula, data = diabetic.sub, subset = train,
mtry = 6, importance = TRUE)
rf
# The output, since it takes too damn long to run.
# Type of random forest: classification
# Number of trees: 500
# No. of variables tried at each split: 6
#
# OOB estimate of  error rate: 38.89%
# Confusion matrix:
#   FALSE  TRUE class.error
# FALSE 13348 15531   0.5377956
# TRUE   9443 25900   0.2671816
rf.predict = predict(rf, newdata = diabetic.sub[test,])
cat("\nConfusion matrix using the test set\n")
table(rf.predict, diabetic.sub$isReadmitted[test])
# The output
# rf.predict FALSE  TRUE
# FALSE  5616  3940
# TRUE   6774 11195
num.correct = sum(rf.predict==diabetic.sub$isReadmitted[test])
num.total = length(test)
accuracy = num.correct/num.total
cat("\nAccuracy\n")
accuracy
# The output,
# 0.6107539
cat("\nCalculate importance of the variables\n")
importance(rf)
sink()  # stop writing to text file
par(mfrow=c(1,2))
png(filename="randomforest.png")  # save plot
varImpPlot(rf)
## end ----------------------------------------------------
# plot the random forest
plot(rf.predict, diabetic.sub$isReadmitted[test])
# abline(0,1)  # not used because we are predicting binary response
dev.off()
varImpPlot(rf)
par(mfrow=c(1,1))
png(filename="rfImportance.png")  # save plot
varImpPlot(rf)
dev.off()
length(nn.2$coefnames)  # number of features
#cat("Fit multinomial logistic neural net and get number of features
#    in model, probabilities, and effective DF\n")
length(nn.1$coefnames)  # number of features
#cat("\nMSE\n")
mse.1
summary(nn.1$fitted.values)
caret::confusionMatrix(as.factor(nn.class.1),
as.factor(diabetic[-train,]$readmitted))
library(nnet)
library(pscl)
resetData <- reset()  # reset data
diabetic <- resetData[[1]]
train <- resetData[[2]]
get <- resetData[[3]]
# use formula from above logit but for readmitted, not isReadmitted
formula <- paste(c("readmitted",varnames), collapse = "~")
# fit multinomial
nn.1 <- multinom(formula, data = diabetic[train,])
#cat("Fit multinomial logistic neural net and get number of features
#    in model, probabilities, and effective DF\n")
length(nn.1$coefnames)  # number of features
summary(nn.1$fitted.values)
nn.1$edf  # effective DF exhausted up by model
#nn.1$deviance  # residual deviance, minus twice log-likelihook
#nn.1$AIC  # AIC for fit
# predict probability of days between readmission using test data
nn.pred.1 <- predict(nn.1, newdata = diabetic[-train,], type = "probs")
# predict intervals between readmission using test data
nn.class.1 <- predict(nn.1, newdata = diabetic[-train,])
#cat("\nConfusion matrix\n")
# confusion matrix
library(caret)
caret::confusionMatrix(as.factor(nn.class.1),
as.factor(diabetic[-train,]$readmitted))
# test error
mse.4 <- mean(as.character(nn.class.1)!=
as.character(diabetic[-train,]$readmitted), na.rm = T)
#cat("\nMSE\n")
mse.4
coef(lasso.1)
nn.2$coefnames
names(olsLasso.1)
#cat("\nDo OLS on training set using selected variables from LASSO\n")
summary(olsLasso.1)$coefficients
#cat("\nDo OLS on training set using selected variables from LASSO\n")
summary(olsLasso.1)$coefficients[,1]
nn.2$coefnames
